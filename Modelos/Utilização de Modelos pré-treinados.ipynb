{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2326609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import \\\n",
    "preprocess_input, decode_predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d37e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o modelo pré-treinado ResNet50 \n",
    "modelo = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29507f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/FIC_DL/imagens/'\n",
    "\n",
    "# Usa uma imagem qualquer, redimensionando para a configuração de entrada da ResNet50\n",
    "img = image.load_img(path + '_form.jpg', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "#imagem_teste.jpg, _strange2.jpg, _form.jpg, ele_.jpg, on_.jpg, tuc_.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba5dd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 90.061  , 112.221  , 108.32   ],\n",
       "         [ 89.061  , 109.221  , 105.32   ],\n",
       "         [ 92.061  , 112.221  , 108.32   ],\n",
       "         ...,\n",
       "         [ 98.061  , 107.221  , 105.32   ],\n",
       "         [ 98.061  , 107.221  , 105.32   ],\n",
       "         [103.061  , 112.221  , 110.32   ]],\n",
       "\n",
       "        [[ 81.061  , 103.221  ,  99.32   ],\n",
       "         [ 81.061  , 101.221  ,  97.32   ],\n",
       "         [ 84.061  , 104.221  , 100.32   ],\n",
       "         ...,\n",
       "         [ 93.061  , 102.221  , 100.32   ],\n",
       "         [ 93.061  , 102.221  , 100.32   ],\n",
       "         [ 97.061  , 106.221  , 104.32   ]],\n",
       "\n",
       "        [[ 81.061  , 103.221  ,  99.32   ],\n",
       "         [ 78.061  , 100.221  ,  96.32   ],\n",
       "         [ 81.061  , 103.221  ,  99.32   ],\n",
       "         ...,\n",
       "         [ 89.061  ,  98.221  ,  96.32   ],\n",
       "         [ 89.061  ,  98.221  ,  96.32   ],\n",
       "         [ 96.061  , 105.221  , 103.32   ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[139.061  , 121.221  , 113.32   ],\n",
       "         [134.061  , 116.221  , 108.32   ],\n",
       "         [132.061  , 114.221  , 106.32   ],\n",
       "         ...,\n",
       "         [132.061  , 112.221  , 102.32   ],\n",
       "         [131.061  , 111.221  , 101.32   ],\n",
       "         [139.061  , 119.221  , 109.32   ]],\n",
       "\n",
       "        [[140.061  , 122.221  , 114.32   ],\n",
       "         [134.061  , 116.221  , 108.32   ],\n",
       "         [131.061  , 113.221  , 105.32   ],\n",
       "         ...,\n",
       "         [135.061  , 115.221  , 105.32   ],\n",
       "         [134.061  , 114.221  , 104.32   ],\n",
       "         [138.061  , 118.221  , 108.32   ]],\n",
       "\n",
       "        [[146.061  , 128.22101, 120.32   ],\n",
       "         [140.061  , 122.221  , 114.32   ],\n",
       "         [139.061  , 121.221  , 113.32   ],\n",
       "         ...,\n",
       "         [142.061  , 122.221  , 112.32   ],\n",
       "         [138.061  , 118.221  , 108.32   ],\n",
       "         [146.061  , 126.221  , 116.32   ]]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73731037",
   "metadata": {},
   "source": [
    "Faz a predição feita pelo modelo pré-treinado da classe da imagem escolhida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ef81d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 132ms/step\n",
      "Predição: [('n02219486', 'ant', 0.999998), ('n01774384', 'black_widow', 1.1444974e-06), ('n01773549', 'barn_spider', 2.536994e-07), ('n02167151', 'ground_beetle', 1.9866506e-07), ('n03530642', 'honeycomb', 1.7552675e-07)]\n"
     ]
    }
   ],
   "source": [
    "preds = modelo.predict(x)\n",
    "print('Predição:', decode_predictions(preds, top=5)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85b1ef31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 conv1_pad\n",
      "2 conv1_conv\n",
      "3 conv1_bn\n",
      "4 conv1_relu\n",
      "5 pool1_pad\n",
      "6 pool1_pool\n",
      "7 conv2_block1_1_conv\n",
      "8 conv2_block1_1_bn\n",
      "9 conv2_block1_1_relu\n",
      "10 conv2_block1_2_conv\n",
      "11 conv2_block1_2_bn\n",
      "12 conv2_block1_2_relu\n",
      "13 conv2_block1_0_conv\n",
      "14 conv2_block1_3_conv\n",
      "15 conv2_block1_0_bn\n",
      "16 conv2_block1_3_bn\n",
      "17 conv2_block1_add\n",
      "18 conv2_block1_out\n",
      "19 conv2_block2_1_conv\n",
      "20 conv2_block2_1_bn\n",
      "21 conv2_block2_1_relu\n",
      "22 conv2_block2_2_conv\n",
      "23 conv2_block2_2_bn\n",
      "24 conv2_block2_2_relu\n",
      "25 conv2_block2_3_conv\n",
      "26 conv2_block2_3_bn\n",
      "27 conv2_block2_add\n",
      "28 conv2_block2_out\n",
      "29 conv2_block3_1_conv\n",
      "30 conv2_block3_1_bn\n",
      "31 conv2_block3_1_relu\n",
      "32 conv2_block3_2_conv\n",
      "33 conv2_block3_2_bn\n",
      "34 conv2_block3_2_relu\n",
      "35 conv2_block3_3_conv\n",
      "36 conv2_block3_3_bn\n",
      "37 conv2_block3_add\n",
      "38 conv2_block3_out\n",
      "39 conv3_block1_1_conv\n",
      "40 conv3_block1_1_bn\n",
      "41 conv3_block1_1_relu\n",
      "42 conv3_block1_2_conv\n",
      "43 conv3_block1_2_bn\n",
      "44 conv3_block1_2_relu\n",
      "45 conv3_block1_0_conv\n",
      "46 conv3_block1_3_conv\n",
      "47 conv3_block1_0_bn\n",
      "48 conv3_block1_3_bn\n",
      "49 conv3_block1_add\n",
      "50 conv3_block1_out\n",
      "51 conv3_block2_1_conv\n",
      "52 conv3_block2_1_bn\n",
      "53 conv3_block2_1_relu\n",
      "54 conv3_block2_2_conv\n",
      "55 conv3_block2_2_bn\n",
      "56 conv3_block2_2_relu\n",
      "57 conv3_block2_3_conv\n",
      "58 conv3_block2_3_bn\n",
      "59 conv3_block2_add\n",
      "60 conv3_block2_out\n",
      "61 conv3_block3_1_conv\n",
      "62 conv3_block3_1_bn\n",
      "63 conv3_block3_1_relu\n",
      "64 conv3_block3_2_conv\n",
      "65 conv3_block3_2_bn\n",
      "66 conv3_block3_2_relu\n",
      "67 conv3_block3_3_conv\n",
      "68 conv3_block3_3_bn\n",
      "69 conv3_block3_add\n",
      "70 conv3_block3_out\n",
      "71 conv3_block4_1_conv\n",
      "72 conv3_block4_1_bn\n",
      "73 conv3_block4_1_relu\n",
      "74 conv3_block4_2_conv\n",
      "75 conv3_block4_2_bn\n",
      "76 conv3_block4_2_relu\n",
      "77 conv3_block4_3_conv\n",
      "78 conv3_block4_3_bn\n",
      "79 conv3_block4_add\n",
      "80 conv3_block4_out\n",
      "81 conv4_block1_1_conv\n",
      "82 conv4_block1_1_bn\n",
      "83 conv4_block1_1_relu\n",
      "84 conv4_block1_2_conv\n",
      "85 conv4_block1_2_bn\n",
      "86 conv4_block1_2_relu\n",
      "87 conv4_block1_0_conv\n",
      "88 conv4_block1_3_conv\n",
      "89 conv4_block1_0_bn\n",
      "90 conv4_block1_3_bn\n",
      "91 conv4_block1_add\n",
      "92 conv4_block1_out\n",
      "93 conv4_block2_1_conv\n",
      "94 conv4_block2_1_bn\n",
      "95 conv4_block2_1_relu\n",
      "96 conv4_block2_2_conv\n",
      "97 conv4_block2_2_bn\n",
      "98 conv4_block2_2_relu\n",
      "99 conv4_block2_3_conv\n",
      "100 conv4_block2_3_bn\n",
      "101 conv4_block2_add\n",
      "102 conv4_block2_out\n",
      "103 conv4_block3_1_conv\n",
      "104 conv4_block3_1_bn\n",
      "105 conv4_block3_1_relu\n",
      "106 conv4_block3_2_conv\n",
      "107 conv4_block3_2_bn\n",
      "108 conv4_block3_2_relu\n",
      "109 conv4_block3_3_conv\n",
      "110 conv4_block3_3_bn\n",
      "111 conv4_block3_add\n",
      "112 conv4_block3_out\n",
      "113 conv4_block4_1_conv\n",
      "114 conv4_block4_1_bn\n",
      "115 conv4_block4_1_relu\n",
      "116 conv4_block4_2_conv\n",
      "117 conv4_block4_2_bn\n",
      "118 conv4_block4_2_relu\n",
      "119 conv4_block4_3_conv\n",
      "120 conv4_block4_3_bn\n",
      "121 conv4_block4_add\n",
      "122 conv4_block4_out\n",
      "123 conv4_block5_1_conv\n",
      "124 conv4_block5_1_bn\n",
      "125 conv4_block5_1_relu\n",
      "126 conv4_block5_2_conv\n",
      "127 conv4_block5_2_bn\n",
      "128 conv4_block5_2_relu\n",
      "129 conv4_block5_3_conv\n",
      "130 conv4_block5_3_bn\n",
      "131 conv4_block5_add\n",
      "132 conv4_block5_out\n",
      "133 conv4_block6_1_conv\n",
      "134 conv4_block6_1_bn\n",
      "135 conv4_block6_1_relu\n",
      "136 conv4_block6_2_conv\n",
      "137 conv4_block6_2_bn\n",
      "138 conv4_block6_2_relu\n",
      "139 conv4_block6_3_conv\n",
      "140 conv4_block6_3_bn\n",
      "141 conv4_block6_add\n",
      "142 conv4_block6_out\n",
      "143 conv5_block1_1_conv\n",
      "144 conv5_block1_1_bn\n",
      "145 conv5_block1_1_relu\n",
      "146 conv5_block1_2_conv\n",
      "147 conv5_block1_2_bn\n",
      "148 conv5_block1_2_relu\n",
      "149 conv5_block1_0_conv\n",
      "150 conv5_block1_3_conv\n",
      "151 conv5_block1_0_bn\n",
      "152 conv5_block1_3_bn\n",
      "153 conv5_block1_add\n",
      "154 conv5_block1_out\n",
      "155 conv5_block2_1_conv\n",
      "156 conv5_block2_1_bn\n",
      "157 conv5_block2_1_relu\n",
      "158 conv5_block2_2_conv\n",
      "159 conv5_block2_2_bn\n",
      "160 conv5_block2_2_relu\n",
      "161 conv5_block2_3_conv\n",
      "162 conv5_block2_3_bn\n",
      "163 conv5_block2_add\n",
      "164 conv5_block2_out\n",
      "165 conv5_block3_1_conv\n",
      "166 conv5_block3_1_bn\n",
      "167 conv5_block3_1_relu\n",
      "168 conv5_block3_2_conv\n",
      "169 conv5_block3_2_bn\n",
      "170 conv5_block3_2_relu\n",
      "171 conv5_block3_3_conv\n",
      "172 conv5_block3_3_bn\n",
      "173 conv5_block3_add\n",
      "174 conv5_block3_out\n",
      "175 avg_pool\n",
      "176 predictions\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(modelo.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6427293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07f43b37",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f68b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91f4124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso do modelo pré-treinado da RESNET\n",
    "modelo = models.resnet50(weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168e5f2",
   "metadata": {},
   "source": [
    "Aplicação de Data augmentation e normalização com uso das configurações de média e desvio padrão da RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9d36f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/FIC_DL/imagens/'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c457801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Carrega uma imagem e pre-processa para o modelo da RESNET50 \n",
    "img = Image.open(path + 'arara.jpg')\n",
    "img = transform(img)\n",
    "x = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fd599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a751608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tensor([[88, 87, 90]]) tensor([[9.9970e-01, 1.2698e-04, 1.0411e-04]])\n"
     ]
    }
   ],
   "source": [
    "# Realiza a predição da classe usando o modelo pré-treinado com as top-3 probabilidades\n",
    "modelo.eval()\n",
    "with torch.no_grad():\n",
    "    preds = modelo(x)\n",
    "probs = torch.nn.functional.softmax(preds, dim=1)\n",
    "top_probs, top_idxs = torch.topk(probs, k=3)\n",
    "print('Predicted:', top_idxs, top_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "193720c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae866a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('imagenet_classes.txt', <http.client.HTTPMessage at 0x1eadc0f58d0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dos arquivos de rótulos da imagenet \n",
    "url = \"https://raw.githubusercontent.com/pytorch/hub/\\\n",
    "master/imagenet_classes.txt\"\n",
    "urllib.request.urlretrieve(url, \"imagenet_classes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f84c2998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c19e4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo pré-treinado da ResNet50\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b101250f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configura o modelo para modo de validação \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "49622e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura as transformações de preprocessamento da imagem \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bd94d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega uma imagem e preprocessa para o modelo da ResNet50\n",
    "path = 'E:/FIC_DL/imagens/'\n",
    "img = Image.open(path + '_dc.jpg')\n",
    "img_tensor = transform(img)\n",
    "img_tensor = img_tensor.unsqueeze(0) # Adiciona  batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "48d5e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa o modelo pré-treinado para predizer a classe da imagem\n",
    "with torch.no_grad():\n",
    "    preds = model(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bfdc5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.nn.functional.softmax(preds, dim=1)\n",
    "top_k_probs, top_k_indices = torch.topk(probs, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d93099f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2050, 0.0925, 0.0705, 0.0443, 0.0343]]),\n",
       " tensor([[281, 904, 285, 282, 207]]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_probs, top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1152fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os rótulos das classes da ImageNet\n",
    "with open('imagenet_classes.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "da29415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "09565d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabby:    0.2050\n",
      "window screen:    0.0925\n",
      "Egyptian cat:    0.0705\n",
      "tiger cat:    0.0443\n",
      "golden retriever:    0.0343\n"
     ]
    }
   ],
   "source": [
    "# Mostra as predições top-k com os rótulos das predições\n",
    "for i in range(len(top_k_probs[0])):\n",
    "    print(f\"{labels[top_k_indices[0][i]]}:\\\n",
    "    {top_k_probs[0][i].item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5d892284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9595e-01, 4.0333e-03, 4.2964e-06, 2.6416e-06, 1.9082e-06]]) tensor([[ 96,  93,  88, 145,  84]])\n",
      "toucan: 0.9960\n",
      "hornbill: 0.0040\n",
      "macaw: 0.0000\n",
      "king penguin: 0.0000\n",
      "peacock: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Carrega o modelo pré-treinado da ResNet50\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Configura o modelo para modo de validação \n",
    "model.eval()\n",
    "\n",
    "# Configura as transformações de preprocessamento da imagem \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Carrega uma imagem e preprocess para o modelo da ResNet50\n",
    "path = 'E:/FIC_DL/imagens/'\n",
    "img = Image.open(path + 'tucano3.png')\n",
    "img_tensor = transform(img)\n",
    "img_tensor = img_tensor.unsqueeze(0) # Adiciona  Add batch dimension\n",
    "#img_tensor = img_tensor.to(device='cuda') # Move tensor to GPU if available\n",
    "\n",
    "# Usa o modelo pré-treinado para predizer a classe da imagem\n",
    "with torch.no_grad():\n",
    "    preds = model(img_tensor)\n",
    "\n",
    "print(top_k_probs, top_k_indices)\n",
    "\n",
    "# Converte os logits das probabilidades e extrai as top k predições\n",
    "probs = torch.nn.functional.softmax(preds, dim=1)\n",
    "top_k_probs, top_k_indices = torch.topk(probs, k=5)\n",
    "\n",
    "# Carrega os rótulos das classes da ImageNet\n",
    "with open('imagenet_classes.txt') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Mostra as predições top-k com os rótulos das predições\n",
    "for i in range(len(top_k_probs[0])):\n",
    "    print(f\"{labels[top_k_indices[0][i]]}: {top_k_probs[0][i].item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e887f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aac85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c1255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4bb341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2d92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60633b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a4dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
